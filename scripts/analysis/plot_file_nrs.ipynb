{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a5964ce-b8f4-413c-abe4-8247dc7e5866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 377 NSL letters\n",
      "[[ 2013. 19212.]\n",
      " [ 2014. 16348.]\n",
      " [ 2015. 12870.]\n",
      " [ 2016. 12150.]\n",
      " [ 2017. 12762.]\n",
      " [ 2018. 10235.]\n",
      " [ 2019. 13850.]\n",
      " [ 2020.  9682.]\n",
      " [ 2021. 12362.]\n",
      " [ 2022. 10941.]]\n",
      "Processing Issued NSL\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m smallest_file_number\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Issued NSL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m astr_nsls_issued_y_axis_offset \u001b[38;5;241m=\u001b[39m \u001b[43mfind_smallest_relevant_file_nr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mastr_nsls_issued\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m astr_nsls_issued_x_axis_time, astr_nsls_issued_y_axis_cumulative_number \u001b[38;5;241m=\u001b[39m get_cumulative_data_over_years(astr_nsls_issued, astr_nsls_issued_y_axis_offset\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(astr_nsls_issued)))\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing ROIs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [22], line 79\u001b[0m, in \u001b[0;36mfind_smallest_relevant_file_nr\u001b[0;34m(data, year)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m year \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(data\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m---> 79\u001b[0m cutoff \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m smallest_file_number_timestamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     81\u001b[0m smallest_file_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# This file plots NSL file numbers and compares them to ASTR data\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from nsl_class import NSL\n",
    "\n",
    "# Optionally, truncate older (and very sparse) data\n",
    "MIN_YEAR = None\n",
    "\n",
    "# NSL data sources\n",
    "NSL_CSV_FILE_PATHS = [\n",
    "    \"../../data/extracted/nsl_letters_google.csv\",\n",
    "    \"../../data/extracted/nsl_letters_apple.csv\",\n",
    "    \"../../data/extracted/nsl_letters_nslarchive.csv\"\n",
    "]\n",
    "\n",
    "# Merge all CSVs into one pandas data frame\n",
    "nsls_df = pd.concat(map(pd.read_csv, NSL_CSV_FILE_PATHS), ignore_index=True)\n",
    "\n",
    "# Drop letters with unknown NSL number\n",
    "nsls_df.dropna(subset=['file number'], inplace=True)\n",
    "print(f\"Parsed {len(nsls_df)} NSL letters\")\n",
    "\n",
    "# Extract issue date and nsl file number from data frame\n",
    "public_available_nsls_x_axis_issue_date = []\n",
    "public_available_nsls_y_axis_nsl_number = []\n",
    "for nsl_index, nsl_row in nsls_df.iterrows():\n",
    "    issue_date = NSL.parse_strftime(nsl_row['issue date'])\n",
    "    # If we use a cutoff, and this letter is outside of the used range, discard\n",
    "    if MIN_YEAR != None and issue_date.year < MIN_YEAR:\n",
    "        continue\n",
    "\n",
    "    public_available_nsls_x_axis_issue_date.append(issue_date)\n",
    "    public_available_nsls_y_axis_nsl_number.append(NSL.parse_file_number(nsl_row['file number']))\n",
    "\n",
    "# Read ASTR data from CSV\n",
    "ASTR_CSV_PATH = \"../../data/extracted/fisa_astr_data.csv\"\n",
    "astr_df = pd.read_csv(ASTR_CSV_PATH)\n",
    "\n",
    "# Create a dictionary with the year as key and the data column as values\n",
    "astr_nsls_issued = dict(astr_df[[\"year\", \"ASTR issued NSLs\"]].dropna().values)\n",
    "astr_rois = dict(astr_df[[\"year\", \"ASTR ROIs\"]].dropna().values)\n",
    "\n",
    "# Make keys integer\n",
    "astr_nsls_issued = {int(k): v for k, v in astr_nsls_issued.items()}\n",
    "astr_rois = {int(k): v for k, v in astr_rois.items()}\n",
    "\n",
    "def get_cumulative_data_over_years(data, base_number_of_nsls=0):\n",
    "    \"\"\"\n",
    "    Expects `data` to have data per year.\n",
    "    Computes the cumulative sum of entries in data: \n",
    "    data[0], data[0] + data[1], data[0] + data[1] + data[2], etc.\n",
    "    \"\"\"\n",
    "    x_axis_time = []\n",
    "    y_axis_total_nsls = []\n",
    "    # start with base_number_of_nsls if not 0\n",
    "    total_number_of_nsls = base_number_of_nsls\n",
    "    for year, number in data.items():\n",
    "        total_number_of_nsls += number\n",
    "        x_axis_time.append(datetime(year=year, month=12, day=31))\n",
    "        y_axis_total_nsls.append(total_number_of_nsls)\n",
    "    return x_axis_time, y_axis_total_nsls\n",
    "\n",
    "def find_smallest_relevant_file_nr(data=None, year=None):\n",
    "    \"\"\"\n",
    "    Expects data to have years as keys.\n",
    "\n",
    "    Find the smallest file number with a timestamp that is\n",
    "    just before the oldest timestamp in data, or before year.\n",
    "    \"\"\"\n",
    "\n",
    "    # Take the year of the oldest entry in data.\n",
    "    if year == None:\n",
    "        year = min(data.keys())\n",
    "    \n",
    "    cutoff = datetime(year=year, month=1, day=1)\n",
    "    smallest_file_number_timestamp = None\n",
    "    smallest_file_number = None\n",
    "    # Go through all NSLs to find the oldest one above the cutoff date\n",
    "    for i, nsl_issue_date in enumerate(public_available_nsls_x_axis_issue_date):\n",
    "        # Update variable if older NSL above cutoff date was found\n",
    "        if cutoff <= nsl_issue_date and (smallest_file_number_timestamp == None or nsl_issue_date <= smallest_file_number_timestamp):\n",
    "            # In case two NSLs are issued on the same day, take the one with the smaller file number\n",
    "            if smallest_file_number == None or public_available_nsls_y_axis_nsl_number[i] < smallest_file_number:\n",
    "                smallest_file_number_timestamp = nsl_issue_date\n",
    "                smallest_file_number = public_available_nsls_y_axis_nsl_number[i]\n",
    "\n",
    "    return smallest_file_number\n",
    "\n",
    "print(\"Processing Issued NSL\")\n",
    "astr_nsls_issued_y_axis_offset = find_smallest_relevant_file_nr(astr_nsls_issued)\n",
    "astr_nsls_issued_x_axis_time, astr_nsls_issued_y_axis_cumulative_number = get_cumulative_data_over_years(astr_nsls_issued, astr_nsls_issued_y_axis_offset-next(iter(astr_nsls_issued)))\n",
    "\n",
    "print(\"Processing ROIs\")\n",
    "astr_rois_y_axis_offset = find_smallest_relevant_file_nr(astr_rois)\n",
    "astr_rois_in_nsls_x_axis_time, astr_rois_in_nsls_y_axis_cumulative_number = get_cumulative_data_over_years(astr_rois, astr_rois_y_axis_offset-next(iter(astr_rois)))\n",
    "\n",
    "\n",
    "#\n",
    "# Plotting\n",
    "#\n",
    "plt.rc(\"axes\", axisbelow=True)\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.rcParams[\"mathtext.default\"] = \"regular\"\n",
    "plt.rcParams[\"figure.figsize\"] = (14,8)\n",
    "\n",
    "colors = [\"#afed89\", \"#ffc1cc\", \"#ebc197\", \"#95c0ef\", \"#8561a1\", \n",
    "            \"#edc895\", \"#2c7707\", \"#9c9ed1\", \"#ccab0a\"]\n",
    "\n",
    "def to_ordinal(xs):\n",
    "    return list(map(lambda x: x.toordinal(), xs))\n",
    "\n",
    "def poly_regression(xs, ys, deg=1):\n",
    "    \"\"\"\n",
    "    Compute regression on xs, ys with polynomial of degree `deg`\n",
    "    (for deg=1, this computes the linear regression)\n",
    "    \"\"\"                                                                                                                                                                                                        \n",
    "    print(f\"Use degree {deg} polyfit\")\n",
    "    x_vals = np.array(xs)\n",
    "    coeffs = np.polyfit(xs, np.array(ys), deg=deg)\n",
    "    new_xs = np.linspace(xs[0], xs[-1], len(x_vals))\n",
    "    new_ys = []\n",
    "    for x in new_xs:\n",
    "        y = 0\n",
    "        for i, coeff in enumerate(coeffs):\n",
    "            y += x**(deg-i) * coeff\n",
    "        new_ys.append(y)\n",
    "\n",
    "    return new_xs, new_ys\n",
    "\n",
    "def plot_regression(ax, xs, ys, deg=1, label=None):\n",
    "    \"\"\"\n",
    "    Add a line with the polynomial regression of degree `deg` to axis `ax`\n",
    "    \"\"\"\n",
    "    regression_xs, regression_ys = poly_regression(xs, ys)                                                                                                                                                               \n",
    "    ax1.plot(regression_xs, regression_ys, linestyle=\"--\", color=\"#d52d2a\", label=label, linewidth=1)\n",
    "\n",
    "# sort file numbers\n",
    "public_available_nsls_x_axis_issue_date_ordinal = to_ordinal(public_available_nsls_x_axis_issue_date)\n",
    "sorted_public_available_nsls_plotting_data = sorted(zip(public_available_nsls_x_axis_issue_date_ordinal, public_available_nsls_y_axis_nsl_number), key=lambda x: x[0])\n",
    "public_available_nsls_x_axis_issue_date_sorted, public_available_nsls_y_axis_nsl_number_sorted = map(list, list(zip(*sorted_public_available_nsls_plotting_data)))\n",
    "\n",
    "# Plotting the numbers acquired from different sources\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# nsl numbers from publicly available nsl files\n",
    "plt.scatter(public_available_nsls_x_axis_issue_date_sorted, public_available_nsls_y_axis_nsl_number_sorted, color=colors[0], marker=\"x\", label=\"NSL file nrs\")\n",
    "plot_regression(ax1, public_available_nsls_x_axis_issue_date_sorted, public_available_nsls_y_axis_nsl_number_sorted, label=\"linear regression\")\n",
    "\n",
    "# number reported in astar\n",
    "plt.plot(to_ordinal(astr_nsls_issued_x_axis_time), astr_nsls_issued_y_axis_cumulative_number, colors[3], marker=\"x\", label=\"ASTR #issued NSLs\")\n",
    "plot_regression(ax1, to_ordinal(astr_nsls_issued_x_axis_time), astr_nsls_issued_y_axis_cumulative_number)\n",
    "\n",
    "# rois reported in astar\n",
    "plt.plot(to_ordinal(astr_rois_in_nsls_x_axis_time), astr_rois_in_nsls_y_axis_cumulative_number, colors[4], marker=\"x\", label=\"ASTR ROIs in NSLs\")\n",
    "plot_regression(ax1, to_ordinal(astr_rois_in_nsls_x_axis_time), astr_rois_in_nsls_y_axis_cumulative_number)\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "x_ticks = ax.get_xticks()\n",
    "\n",
    "# set plot xticklabels\n",
    "new_labels = [datetime.fromordinal(int(item)).year for item in ax.get_xticks()]\n",
    "ax.set_xticklabels(new_labels)\n",
    "\n",
    "# Save\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"file numbers | cummulative count\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "\n",
    "OUTPUT_DATA_DIR = \"../../data/processed/\"\n",
    "plt.savefig(\"{}/file_numbers.pdf\".format(OUTPUT_DATA_DIR))\n",
    "plt.savefig(\"{}/file_numbers.png\".format(OUTPUT_DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfe180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
